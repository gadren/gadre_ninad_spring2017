{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "Use nps_chat and wordlist corpus.\n",
    "If you find a word in nps_chat but not in wordlist, it is considered an unusual word. (e.g. Heyyyy, gr8, 4ever can be considered unusual words for this analysis)\n",
    "Find out how many unusual words people speak in chat (notice: usernames should not be counted)\n",
    "Bonus: What if I want to  count : ) , : ( all these emoticons in. (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-19-20s_706posts.xml',\n",
       " '10-19-30s_705posts.xml',\n",
       " '10-19-40s_686posts.xml',\n",
       " '10-19-adults_706posts.xml',\n",
       " '10-24-40s_706posts.xml',\n",
       " '10-26-teens_706posts.xml',\n",
       " '11-06-adults_706posts.xml',\n",
       " '11-08-20s_705posts.xml',\n",
       " '11-08-40s_706posts.xml',\n",
       " '11-08-adults_705posts.xml',\n",
       " '11-08-teens_706posts.xml',\n",
       " '11-09-20s_706posts.xml',\n",
       " '11-09-40s_706posts.xml',\n",
       " '11-09-adults_706posts.xml',\n",
       " '11-09-teens_706posts.xml']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.corpus.nps_chat.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words is 3037. The first 10 are:\n",
      "['hugggs', 'ack', 'cyber.', 'mm', 'hahaha', 'oo', 'bishes', 'cares', 'heyy', 'eggs']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "chat_files = nltk.corpus.nps_chat.fileids()\n",
    "wordlist = nltk.corpus.words.words()\n",
    "wordlist = [word.lower() for word in wordlist]\n",
    "for i in range(len(chat_files)):\n",
    "    words += nltk.corpus.nps_chat.words(chat_files[i])\n",
    "words = set(words)\n",
    "words= [word.lower() for word in words]\n",
    "words = removeStopPunc(words)\n",
    "words = removeUserNames(words)\n",
    "unique = [word for word in words if word not in wordlist]\n",
    "print(\"The number of unique words is %s. The first 10 are:\"%(len(unique)))\n",
    "print(unique[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeUserNames(word_list):\n",
    "    abc = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "    word_list = [word for word in word_list if not (len(word) > 1 and word[0]==\"u\" and word[1] not in abc)]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeStopPunc(word_list):\n",
    "    abc = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = stopwords.words('english')\n",
    "    word_list = [word for word in word_list if (len(word) > 0)]\n",
    "    word_list = [word for word in word_list if (word not in stopwords)]\n",
    "    word_list = [word for word in word_list if not (word[0] not in abc and len(word) == 1)]#keeps ;)\n",
    "    return word_list"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
